{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae8c399-a17e-484e-8c01-eba550defd83",
   "metadata": {},
   "source": [
    "# Week 3: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2216a21a-227a-47fc-8ea3-3bfe2a13866a",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "![logistic regression definition](../images/lr1.png)\n",
    "\n",
    "![logistic regression interpretation](../images/lr2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae567ca-f123-4557-b581-1990c16aecd9",
   "metadata": {},
   "source": [
    "### Decision Boundary\n",
    "\n",
    "![logistic regression decision boundary](../images/lreg_db.png)\n",
    "\n",
    "![logistic regression decision boundary-linear](../images/lreg_db1.png)\n",
    "\n",
    "![logistic regression decision boundary-nonlinear](../images/lreg_db2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c23f14-bbca-44dd-ba6f-028ff3d9d215",
   "metadata": {},
   "source": [
    "### Cost function for logistic regression\n",
    "\n",
    "Here is the problem with sequared loss function for the logistic regression:\n",
    "\n",
    "![squared cost function](../images/squared_cost_function.png)\n",
    "\n",
    "We need another function to estimate the loss function for logistic regression:\n",
    "\n",
    "![log-loss loss function1](../images/lreg_loss_function1.png)\n",
    "\n",
    "![log-loss loss function1](../images/lreg_loss_function2.png)\n",
    "\n",
    "![log-loss cost function](../images/lreg_cost_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72813707-5c23-4745-8d3a-6e861ee73144",
   "metadata": {},
   "source": [
    "### Gradient Descent Implementation\n",
    "\n",
    "* **Objective**: To fit a **logistic regression** model, the goal is to find the optimal values for parameters **$w$** and **$b$** that **minimize the cost function**, **$J(w, b)$**, using an optimization algorithm called **gradient descent**.\n",
    "---\n",
    "* **Gradient Descent Algorithm**: The process involves repeatedly updating each parameter (e.g., **$w_j$** and **$b$**) by subtracting the **learning rate ($α$)** multiplied by the **derivative of the cost function** with respect to that parameter.\n",
    "    * **Derivative with respect to $w_j$**: The derivative of the cost function **$J$** with respect to **$w_j$** is given by the expression: $\\frac{1}{m}\\sum_{i=1}^{m} (f^{(i)} - y^{(i)})x_{j}^{(i)}$.\n",
    "    * **Derivative with respect to $b$**: The derivative of the cost function **$J$** with respect to **$b$** is given by the expression: $\\frac{1}{m}\\sum_{i=1}^{m} (f^{(i)} - y^{(i)})$.\n",
    "    * **Simultaneous Updates**: All parameter updates must be calculated first and then applied simultaneously to ensure the algorithm works correctly.\n",
    "---\n",
    "* **Key Distinction from Linear Regression**: Although the gradient descent update equations for logistic regression appear identical to those for linear regression, the algorithms are fundamentally different. This is because the definition of the prediction function, **$f(x)$**, has changed:\n",
    "    * **Linear Regression**: $f(x) = wx + b$\n",
    "    * **Logistic Regression**: $f(x) = \\text{sigmoid}(wx + b)$. The sigmoid function transforms the linear output into a probability between 0 and 1.\n",
    "---\n",
    "* **Best Practices and Convergence**:\n",
    "    * You can monitor gradient descent to ensure it converges, just as in linear regression.\n",
    "    * **Feature scaling**—adjusting features to similar ranges (e.g., -1 to +1)—is highly recommended as it can significantly speed up the convergence of the gradient descent algorithm.\n",
    "    * **Vectorization** can be used to implement gradient descent more efficiently and make it run faster.\n",
    "---\n",
    "\n",
    "![Logistic regression gradient descent](../images/lreg_gradient_descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df11956-0c72-4a23-bbc2-3c3a69cbb1b5",
   "metadata": {},
   "source": [
    "### The Problem of Overfitting\n",
    "\n",
    "#### Underfitting (High Bias)\n",
    "\n",
    "Underfitting occurs when a model is too simple to capture the underlying patterns in the training data. This leads to poor performance on both the training data and new, unseen data. It often results from having too few features or a model that isn't complex enough. The model has a strong, incorrect assumption or \"bias\" about the data's nature. \n",
    "\n",
    "#### Overfitting (High Variance)\n",
    "\n",
    "Overfitting happens when a model is too complex and learns the noise and random fluctuations of the training data instead of just the core patterns. While it performs extremely well on the training data, it fails to **generalize** to new examples. This is also called having \"high variance,\" as the model's predictions are highly sensitive and **variable** to minor changes in the training data. \n",
    "\n",
    "#### The \"Just Right\" Model\n",
    "\n",
    "The goal of machine learning is to find a \"just right\" model—one that avoids both underfitting and overfitting. This model is complex enough to capture the data's main trends but simple enough to ignore the noise, ensuring it can make accurate predictions on new data.\n",
    "\n",
    "---\n",
    "![overfitting](../images/overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b71799-5dc3-4a1c-8121-02b077a62e7e",
   "metadata": {},
   "source": [
    "### Addressing Overfitting\n",
    "\n",
    "To fix an overfitted model (high variance), you can take one of three main actions:\n",
    "\n",
    "#### 1. Get More Data\n",
    "Collecting a larger dataset is the best way to combat overfitting. More data points provide a clearer picture of the underlying patterns, making it harder for the model to just memorize noise and random fluctuations from a small sample. This helps the model generalize better.\n",
    "\n",
    "#### 2. Use Fewer Features\n",
    "If you have many features and a limited amount of data, overfitting is likely. You can manually select a smaller, more relevant subset of features, a process known as **feature selection**. While this can reduce overfitting, it may cause you to lose potentially useful information.\n",
    "\n",
    "#### 3. Regularization\n",
    "Regularization is a powerful and widely used technique that allows you to keep all your features while reducing their impact. It works by adding a penalty to the model's cost function to discourage overly large parameter values (**$w$**). This encourages a simpler, smoother model that is less likely to overfit and performs better on new data.\n",
    "\n",
    "---\n",
    "\n",
    "![Addressing Overfitting](../images/addressing_overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8d8b1-3d2c-4015-beb5-52e71f730eb7",
   "metadata": {},
   "source": [
    "### Cost function with regularization\n",
    "\n",
    "Regularization is a technique used to **reduce overfitting** in machine learning models by adding a penalty term to the cost function. This encourages the model's parameters ($W$) to be small.\n",
    "\n",
    "#### The Regularized Cost Function (L2 Regularization)\n",
    "\n",
    "The standard cost function $J$ is modified by adding a **regularization term** that penalizes large parameter values. This specific form is known as **L2 regularization** (or Ridge Regression in the context of linear models).\n",
    "\n",
    "* **Original Goal:** Minimize the error between predictions and actual values (e.g., Mean Squared Error).\n",
    "* **New Goal:** Minimize the error **AND** keep the $W$ parameters small.\n",
    "\n",
    "The modified cost function is:\n",
    "$$J_{regularized}(\\mathbf{W}, b) = \\underbrace{\\frac{1}{2m} \\sum_{i=1}^{m} (\\text{loss term})}_{\\text{Fit the data well}} + \\underbrace{\\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2}_{\\text{Regularization term (Keep } W \\text{ small)}}$$\n",
    "\n",
    "* **$\\lambda$ (Lambda):** This is the **regularization parameter**, a hyperparameter that controls the trade-off between fitting the training data well (minimizing the first term) and keeping the weights small (minimizing the second term).\n",
    "* **Convention:** By convention, the bias term ($b$) is usually **not** penalized, as it makes very little difference in practice.\n",
    "\n",
    "#### How Regularization Works\n",
    "\n",
    "* **Simpler Model:** Penalizing large $W$ values effectively simplifies the model. By forcing $W$ values close to zero (without eliminating them entirely), the model reduces the influence of those features, resulting in a smoother, less \"wiggly\" function that is less prone to overfitting.\n",
    "* **Trade-off:** The model must balance two conflicting goals:\n",
    "    * **Low $\\lambda$ (e.g., $\\lambda=0$):** No regularization. The model is free to choose large weights, resulting in a complex, wiggly curve that **overfits** the data.\n",
    "    * **High $\\lambda$ (e.g., $\\lambda=10^{10}$):** Heavy penalty. The only way to minimize the cost is to drive all $W$ values close to zero. This simplifies the model excessively, making it too rigid (like a horizontal line), which causes the model to **underfit** the data.\n",
    "    * **Just Right $\\lambda$:** An intermediate value of $\\lambda$ balances the two terms, leading to a model that generalizes well by fitting the data's pattern without overfitting to the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c5aaa-2774-4ca9-94c5-a7c7fc8916c3",
   "metadata": {},
   "source": [
    "### Regularized linear regression\n",
    "\n",
    "Gradient descent for regularized linear regression is an extension of the standard algorithm, incorporating the penalty term for the weights ($W$) to mitigate overfitting.\n",
    "\n",
    "#### Regularized Cost Function\n",
    "The goal is to minimize the regularized cost function, $J(\\mathbf{W}, b)$:\n",
    "$$J(\\mathbf{W}, b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f_{\\mathbf{W}, b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2$$\n",
    "\n",
    "#### Gradient Descent Updates\n",
    "The core gradient descent update rules are modified to include the derivative of the regularization term. Remember that the bias parameter ($b$) is **not** regularized.\n",
    "\n",
    "| Parameter | Update Rule | Notes |\n",
    "| :--- | :--- | :--- |\n",
    "| **$w_j$** | $w_j := w_j - \\alpha \\left[ \\left( \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\mathbf{W}, b}(\\mathbf{x}^{(i)}) - y^{(i)})x_j^{(i)} \\right) + \\frac{\\lambda}{m} w_j \\right]$ | Includes the new $\\frac{\\lambda}{m} w_j$ term to shrink $w_j$. |\n",
    "| **$b$** | $b := b - \\alpha \\left[ \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\mathbf{W}, b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\right]$ | Remains unchanged from unregularized linear regression. |\n",
    "\n",
    "* **Simultaneous Updates:** All $w_j$ and $b$ must be updated simultaneously.\n",
    "* **$f_{\\mathbf{W}, b}(\\mathbf{x}^{(i)})$** is the linear regression prediction: $\\mathbf{w} \\cdot \\mathbf{x} + b$.\n",
    "\n",
    "#### Intuition (Weight Decay)\n",
    "The update rule for $w_j$ can be algebraically rearranged to reveal a clearer interpretation:\n",
    "$$w_j := w_j \\left( 1 - \\alpha \\frac{\\lambda}{m} \\right) - \\alpha \\left( \\frac{1}{m} \\sum_{i=1}^{m} (\\text{Error} \\times x_j^{(i)}) \\right)$$\n",
    "\n",
    "* **Weight Shrinkage:** The term $\\left( 1 - \\alpha \\frac{\\lambda}{m} \\right)$ is a number slightly less than 1 (since $\\alpha$, $\\lambda$, and $m$ are positive).\n",
    "* **Effect:** On every iteration, $w_j$ is multiplied by a number slightly less than 1 before the standard update is applied. This effectively shrinks the value of $w_j$ toward zero, giving the method its alternative name: **Weight Decay**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76481163-8352-4dca-bfc1-83d80dcc7138",
   "metadata": {},
   "source": [
    "### Regularized logistic regression\n",
    "\n",
    "To address overfitting in logistic regression, a **regularization term** is added to the cost function, similar to linear regression.\n",
    "\n",
    "#### Regularized Cost Function\n",
    "\n",
    "The cost function for logistic regression, $J(\\mathbf{W}, b)$, is modified to include the $\\text{L2}$ regularization term:\n",
    "\n",
    "$$J_{regularized}(\\mathbf{W}, b) = \\underbrace{\\frac{1}{m} \\sum_{i=1}^{m} \\left[ -y^{(i)}\\log(f_{\\mathbf{W}, b}(\\mathbf{x}^{(i)})) - (1-y^{(i)})\\log(1-f_{\\mathbf{W}, b}(\\mathbf{x}^{(i)})) \\right]}_{\\text{Original Logistic Regression Cost}} + \\underbrace{\\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2}_{\\text{Regularization Term}}$$\n",
    "\n",
    "* This term $\\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2$ penalizes large values of the weights ($\\mathbf{W}$) to prevent an overly complex decision boundary and improve generalization.\n",
    "* **$f_{\\mathbf{W}, b}(\\mathbf{x})$** is the logistic regression prediction: $g(\\mathbf{w} \\cdot \\mathbf{x} + b)$, where $g$ is the sigmoid function.\n",
    "\n",
    "#### Gradient Descent Updates\n",
    "\n",
    "Gradient descent is used to minimize the new cost function. The update rules for the parameters are almost identical to those for regularized linear regression, but the definition of the prediction function ($f$) is different.\n",
    "\n",
    "* **Update for $w_j$** (for $j=1$ to $n$):\n",
    "    $$w_j := w_j - \\alpha \\left[ \\left( \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\mathbf{W}, b}(\\mathbf{x}^{(i)}) - y^{(i)})x_j^{(i)} \\right) + \\frac{\\lambda}{m} w_j \\right]$$\n",
    "    * The term **$\\frac{\\lambda}{m} w_j$** is the derivative of the regularization term, which ensures that the weights are shrunk toward zero in every iteration.\n",
    "* **Update for $b$** (Bias):\n",
    "    $$b := b - \\alpha \\left[ \\frac{1}{m} \\sum_{i=1}^{m} (f_{\\mathbf{W}, b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\right]$$\n",
    "    * The bias parameter **$b$ is not regularized**, so its update rule remains the same as in the unregularized version.\n",
    "\n",
    "This method allows logistic regression to use many features (including high-order polynomial features) while still finding a simpler, more reasonable **decision boundary** that avoids overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004e9cc-edec-4eee-acf5-8e673637c5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
